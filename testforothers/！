#!/usr/bin/env python
# -*- coding=utf8 -*-
"""
# Author: 你的名字
# Created Time : 2018年02月16日 星期五 21时14分14秒
# File Name: testRE3.py
# Description:爬取百度贴吧：
"""
import urllib
import urllib2
import re
import random
from lxml import etree
class tiebaSpider:
    def __init__(self):
        self.page=2
        self.switch=True
    def loadPage(self,keyword,begin_page,end_page):
        print "正在下载数据"+filename
        fullurl="https://tieba.baidu.com/f?ie=utf-8&kw="+urllib.urlencode(keyword)+'&fr=search'
        print fullurl
        ua_list = [
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv2.0.1) Gecko/20100101 Firefox/4.0.1",
                "Mozilla/5.0 (Windows NT 6.1; rv2.0.1) Gecko/20100101 Firefox/4.0.1",
                "Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11",
                "Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11",
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11",
        ]
        user_agent=random.choice(ua_list)
        request=urllib2.Request(fullurl)
        request.add_header("User-Agent",user_agent)
        # request.get_header("User-agent")#第一个字母大写
        response=urllib2.urlopen(request)
        html=response.read()
        content=etree.HTML(html)
        link_list=content.xpath("//*[@class="p_author_face"]/img/@src")
        username_list=content.xpath("//*[@class="p_author_face"]/img/@username")
        for (link,username) in (link_list,username_list):
            # fulllink="https://tieba.baidu.com"+link
            writeImage(link,username)
    def writeImage(self,link,username):
        headers={"User-Agent":"Mozilla/5.0 (Windows NT 6.1; rv2.0.1) Gecko/20100101 Firefox/4.0.1"}
        request=urllib2.Request(url,headers=headers)
        image=urllib2.urlopen(request).read()
        print "正在写入数据\n"
        with open(username+'.txt', 'wb') as f:
            f.write(image)
        print "*"*30

    def startWork(self):
        # while self.switch:
        tieba_name=raw_input("请输入爬取的贴吧名")
        begin_page=raw_input("请输入起始页")
        end_page=raw_input("请输入结束页")
        self.loadPage(tieba_name,begin_page,end_page)
        self.page+=1


        print "谢谢使用"

if __name__ == '__main__':
    duanziSpider=Spider()
    # duanziSpider.loadPage()
    duanziSpider.startWork()





